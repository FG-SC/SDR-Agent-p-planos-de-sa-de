import streamlit as st
import os
from dotenv import load_dotenv
import asyncio
import grpc
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json

# --- Monkey Patch para gRPC e asyncio ---
_original_secure_channel = grpc.aio.secure_channel
_original_insecure_channel = grpc.aio.insecure_channel

def setup_event_loop():
    try:
        return asyncio.get_event_loop()
    except RuntimeError as ex:
        if "There is no current event loop in thread" in str(ex):
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            return loop

def patched_secure_channel(*args, **kwargs):
    setup_event_loop()
    return _original_secure_channel(*args, **kwargs)

def patched_insecure_channel(*args, **kwargs):
    setup_event_loop()
    return _original_insecure_channel(*args, **kwargs)

grpc.aio.secure_channel = patched_secure_channel
grpc.aio.insecure_channel = patched_insecure_channel

# --- Importa√ß√µes do LangChain ---
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.vectorstores import SupabaseVectorStore
from supabase.client import create_client, Client
from langchain.chains.history_aware_retriever import create_history_aware_retriever
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

# Carrega vari√°veis de ambiente
load_dotenv()

# --- Configura√ß√µes ---
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not all([SUPABASE_URL, SUPABASE_KEY, GOOGLE_API_KEY]):
    st.error("‚ùå Erro: Configure as vari√°veis de ambiente no arquivo .env")
    st.stop()

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Agente SDR Qualicorp/SulAm√©rica", 
    page_icon="üè•", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS Customizado ---
st.markdown("""
<style>
    .main-header {
        padding: 1rem 0;
        background: linear-gradient(90deg, #1f4e79 0%, #2e5c87 100%);
        color: white;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f4e79;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .chat-container {
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 1rem;
        background: #fafafa;
    }
    .quick-action-btn {
        background: #1f4e79;
        color: white;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        margin: 0.2rem;
    }
</style>
""", unsafe_allow_html=True)

# --- Header Principal ---
st.markdown("""
<div class="main-header">
    <h1>üè• Agente SDR Qualicorp/SulAm√©rica</h1>
    <p>Seu assistente inteligente especializado em planos de sa√∫de empresariais</p>
</div>
""", unsafe_allow_html=True)

# --- Gerenciamento do Hist√≥rico ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = ChatMessageHistory()

if "messages" not in st.session_state:
    st.session_state.messages = []

if "session_stats" not in st.session_state:
    st.session_state.session_stats = {
        "queries_count": 0,
        "price_queries": 0,
        "plans_consulted": set(),
        "start_time": datetime.now()
    }

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    return st.session_state.chat_history

@st.cache_resource
def initialize_rag_model():
    """Inicializa o modelo RAG com configura√ß√µes otimizadas."""
    
    with st.spinner("üîÑ Inicializando sistema inteligente..."):
        try:
            # LLM otimizado
            llm = ChatGoogleGenerativeAI(
                model="gemini-2.0-flash",
                google_api_key=GOOGLE_API_KEY,
                temperature=0.1,  # Ainda mais conservador para dados de pre√ßos
                convert_system_message_to_human=True
            )

            # Cliente Supabase
            supabase_client: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

            # Embeddings
            embeddings = GoogleGenerativeAIEmbeddings(
                model="models/text-embedding-004", 
                google_api_key=GOOGLE_API_KEY
            )

            # Vector Store
            vectorstore = SupabaseVectorStore(
                embedding=embeddings,
                client=supabase_client,
                table_name="planos_saude_docs_v2",
                query_name="match_documents_v2"
            )

            # Retriever otimizado
            retriever = vectorstore.as_retriever(
                search_kwargs={"k": 25}  # Mais contexto para an√°lises completas
            )

            # Prompt para contextualiza√ß√£o
            contextualize_q_system_prompt = (
                "Dada uma conversa de chat e a √∫ltima pergunta do usu√°rio, "
                "formule uma pergunta independente que possa ser entendida com o hist√≥rico do chat. "
                "N√ÉO responda √† pergunta, apenas reformule-a se necess√°rio."
            )
            
            contextualize_q_prompt = ChatPromptTemplate.from_messages([
                ("system", contextualize_q_system_prompt),
                MessagesPlaceholder("chat_history"),
                ("human", "{input}"),
            ])
            
            history_aware_retriever = create_history_aware_retriever(
                llm, retriever, contextualize_q_prompt
            )

            # Prompt principal otimizado para SDR
            qa_system_prompt = """
            Voc√™ √© um AI Agent SDR especialista da Qualicorp/SulAm√©rica, focado em vendas consultivas de planos de sa√∫de empresariais.

            **SEUS OBJETIVOS COMO SDR:**
            1. **QUALIFICAR LEADS**: Identificar necessidades espec√≠ficas do cliente
            2. **APRESENTAR SOLU√á√ïES**: Recomendar planos adequados ao perfil
            3. **GERAR INTERESSE**: Destacar benef√≠cios e vantagens competitivas
            4. **CONDUZIR √Ä VENDA**: Orientar pr√≥ximos passos no processo

            **ESTRUTURA DOS DADOS:**
            Os documentos cont√™m informa√ß√µes no formato:
            "Plano: [nome] | Faixa et√°ria: [idade] | Valor mensal: R$ [pre√ßo] | Regi√£o: [local] | Categoria: [dependentes]"

            **REGRAS DE COMUNICA√á√ÉO:**
            ‚úÖ Use APENAS informa√ß√µes do contexto fornecido
            ‚úÖ Seja consultivo, n√£o apenas informativo  
            ‚úÖ Fa√ßa perguntas qualificadoras quando necess√°rio
            ‚úÖ Organize respostas em tabelas quando apropriado
            ‚úÖ Destaque benef√≠cios e diferenciais
            ‚úÖ Sugira pr√≥ximos passos quando relevante

            **PERGUNTAS QUALIFICADORAS T√çPICAS:**
            - Quantos funcion√°rios tem a empresa?
            - Qual faixa et√°ria predominante?
            - J√° possuem plano de sa√∫de? Qual operadora?
            - Or√ßamento m√©dio por funcion√°rio?
            - Regi√£o de atua√ß√£o da empresa?

            **FORMATO DE APRESENTA√á√ÉO:**
            - üìä Tabelas para compara√ß√£o de pre√ßos
            - üí° Destaque de benef√≠cios √∫nicos
            - üéØ Recomenda√ß√µes personalizadas
            - üìû Call-to-action quando apropriado

            **PLANOS DISPON√çVEIS:**
            - **Cl√°ssico**: Entrada, ideal para PMEs
            - **Especial**: Intermedi√°rio, bom custo-benef√≠cio  
            - **Executivo**: Premium, para executivos
            - **Direto**: Acesso direto, sem referenciamento

            **REGI√ïES DE COBERTURA:**
            - Capital SP e Regi√£o Metropolitana
            - Interior (1, 2, 3) - diferentes sub-regi√µes

            **CONTEXTO DA CONSULTA:**
            {context}

            **CONSULTA DO CLIENTE:**
            {input}

            **SUA RESPOSTA CONSULTIVA:**
            """
            
            qa_prompt = ChatPromptTemplate.from_messages([
                ("system", qa_system_prompt),
                MessagesPlaceholder("chat_history"),
                ("human", "{input}"),
            ])

            # Chains
            question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
            rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

            return rag_chain

        except Exception as e:
            st.error(f"‚ùå Erro ao inicializar o sistema: {str(e)}")
            st.stop()

# --- Fun√ß√µes de An√°lise de Dados ---
def create_price_comparison_chart(price_data):
    """Cria gr√°fico de compara√ß√£o de pre√ßos por plano."""
    if not price_data:
        return None
    
    df = pd.DataFrame(price_data)
    
    # Limpa e converte pre√ßos
    df['Pre√ßo_Num'] = df['Pre√ßo'].str.replace('R$ ', '').str.replace(',', '.').astype(float)
    
    fig = px.bar(
        df, 
        x='Faixa Et√°ria', 
        y='Pre√ßo_Num', 
        color='Plano',
        title='Compara√ß√£o de Pre√ßos por Faixa Et√°ria',
        labels={'Pre√ßo_Num': 'Valor (R$)'},
        text='Pre√ßo'
    )
    
    fig.update_layout(
        xaxis_title="Faixa Et√°ria",
        yaxis_title="Valor Mensal (R$)",
        showlegend=True,
        height=400
    )
    
    return fig

def extract_price_data(documents):
    """Extrai dados de pre√ßos dos documentos para an√°lise."""
    price_data = []
    
    for doc in documents:
        if doc.metadata.get('document_type') == 'Tabela de Pre√ßos':
            price_data.append({
                'Plano': doc.metadata.get('plan_name', 'N/A'),
                'Faixa Et√°ria': doc.metadata.get('age_range', 'N/A'),
                'Pre√ßo': f"R$ {doc.metadata.get('price', 'N/A')}",
                'Regi√£o': doc.metadata.get('region', 'N/A'),
                'Categoria': doc.metadata.get('dependents_type', 'N/A'),
                'Pre√ßo_Num': float(doc.metadata.get('price', '0').replace(',', '.')) if doc.metadata.get('price') else 0
            })
    
    return price_data

def update_session_stats(query, context):
    """Atualiza estat√≠sticas da sess√£o."""
    st.session_state.session_stats["queries_count"] += 1
    
    if "R$" in query or "pre√ßo" in query.lower() or "valor" in query.lower():
        st.session_state.session_stats["price_queries"] += 1
    
    # Extrai planos mencionados no contexto
    for doc in context:
        if doc.metadata.get('plan_name'):
            st.session_state.session_stats["plans_consulted"].add(doc.metadata['plan_name'])

# --- Layout Principal ---
col_main, col_sidebar = st.columns([3, 1])

with col_main:
    # --- Inicializa√ß√£o do Sistema ---
    rag_chain = initialize_rag_model()
    st.success("‚úÖ Sistema SDR inicializado e pronto para atendimento!")

    # --- Interface de Chat ---
    st.markdown("### üí¨ Consultor Virtual Qualicorp/SulAm√©rica")
    
    # Container para o chat
    chat_container = st.container()
    
    with chat_container:
        # Exibe hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                if "context" in message and message["context"]:
                    # Cria visualiza√ß√µes dos dados
                    price_data = extract_price_data(message["context"])
                    
                    if price_data:
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            # Tabela organizada
                            df = pd.DataFrame(price_data)
                            st.markdown("#### üìä Comparativo de Pre√ßos")
                            st.dataframe(
                                df[['Plano', 'Faixa Et√°ria', 'Pre√ßo', 'Regi√£o', 'Categoria']],
                                use_container_width=True,
                                hide_index=True
                            )
                        
                        with col2:
                            # M√©tricas r√°pidas
                            if len(price_data) > 1:
                                prices = [p['Pre√ßo_Num'] for p in price_data if p['Pre√ßo_Num'] > 0]
                                if prices:
                                    st.metric("Menor Pre√ßo", f"R$ {min(prices):,.2f}".replace('.', ','))
                                    st.metric("Maior Pre√ßo", f"R$ {max(prices):,.2f}".replace('.', ','))
                                    st.metric("Pre√ßo M√©dio", f"R$ {sum(prices)/len(prices):,.2f}".replace('.', ','))
                    
                    # Expandir para ver fontes detalhadas
                    with st.expander("üìö Fontes Consultadas", expanded=False):
                        for doc in message["context"]:
                            source = doc.metadata.get('source', 'Fonte Desconhecida').replace('.pdf', '')
                            st.markdown(f"**üìÑ {source}** | P√°gina {doc.metadata.get('page', 'N/A')}")
                            st.markdown(f"> *{doc.page_content[:200]}...*")
                            st.markdown("---")

    # --- Input de Chat ---
    if prompt := st.chat_input("üí≠ Ex: Preciso de um plano para empresa com 50 funcion√°rios na faixa de 30-40 anos..."):
        
        # Adiciona mensagem do usu√°rio
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Processa resposta
        with st.chat_message("assistant"):
            with st.spinner("üîç Analisando sua necessidade e consultando nossa base..."):
                try:
                    chat_history = get_session_history("main_chat")
                    
                    # Invoca o RAG
                    response_dict = rag_chain.invoke({
                        "input": prompt, 
                        "chat_history": chat_history.messages
                    })
                    
                    assistant_response = response_dict.get("answer", "‚ùå N√£o consegui processar sua pergunta no momento.")
                    retrieved_context = response_dict.get("context", [])
                    
                    # Atualiza estat√≠sticas
                    update_session_stats(prompt, retrieved_context)
                    
                    # Exibe resposta
                    st.markdown(assistant_response)

                    # An√°lise e visualiza√ß√£o dos dados
                    if retrieved_context:
                        price_data = extract_price_data(retrieved_context)
                        
                        if price_data:
                            col1, col2 = st.columns([2, 1])
                            
                            with col1:
                                # Tabela principal
                                df = pd.DataFrame(price_data)
                                st.markdown("#### üìä Op√ß√µes Encontradas")
                                st.dataframe(
                                    df[['Plano', 'Faixa Et√°ria', 'Pre√ßo', 'Regi√£o', 'Categoria']],
                                    use_container_width=True,
                                    hide_index=True
                                )
                            
                            with col2:
                                # An√°lise r√°pida
                                if len(price_data) > 1:
                                    prices = [p['Pre√ßo_Num'] for p in price_data if p['Pre√ßo_Num'] > 0]
                                    if prices:
                                        st.metric("üí∞ Menor Valor", f"R$ {min(prices):,.2f}".replace('.', ','))
                                        st.metric("üíé Maior Valor", f"R$ {max(prices):,.2f}".replace('.', ','))
                                        st.metric("üìä Valor M√©dio", f"R$ {sum(prices)/len(prices):,.2f}".replace('.', ','))
                                        
                                        # Bot√£o de a√ß√£o
                                        st.markdown("---")
                                        if st.button("üìû Solicitar Proposta", type="primary"):
                                            st.success("‚úÖ Em breve nosso consultor entrar√° em contato!")

                        # Gr√°fico de compara√ß√£o (se houver dados suficientes)
                        if len(price_data) > 3:
                            chart = create_price_comparison_chart(price_data)
                            if chart:
                                st.plotly_chart(chart, use_container_width=True)

                    # Atualiza hist√≥rico
                    chat_history.add_user_message(prompt)
                    chat_history.add_ai_message(assistant_response)
                    
                    # Salva para re-exibi√ß√£o
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": assistant_response,
                        "context": retrieved_context
                    })

                except Exception as e:
                    st.error(f"‚ùå **Erro ao processar solicita√ß√£o:** {str(e)}")

# --- Sidebar Interativa ---
with col_sidebar:
    st.markdown("### üéØ A√ß√µes R√°pidas")
    
    # Bot√µes de consulta r√°pida
    quick_queries = [
        "üíº Planos para PME (10-50 funcion√°rios)",
        "üè¢ Planos corporativos (50+ funcion√°rios)",
        "üë• Comparar Cl√°ssico vs Especial",
        "üìç Cobertura Interior SP",
        "üí∞ Faixas de pre√ßo por idade"
    ]
    
    for query in quick_queries:
        if st.button(query, key=f"quick_{hash(query)}", use_container_width=True):
            # Simula envio da consulta
            st.session_state.pending_query = query.replace("üíº ", "").replace("üè¢ ", "").replace("üë• ", "").replace("üìç ", "").replace("üí∞ ", "")
            st.rerun()

    st.markdown("---")
    
    # Estat√≠sticas da sess√£o
    st.markdown("### üìä Dashboard da Sess√£o")
    
    stats = st.session_state.session_stats
    
    # M√©tricas principais
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Consultas", stats["queries_count"])
    with col2:
        st.metric("Pre√ßos", stats["price_queries"])
    
    # Planos consultados
    if stats["plans_consulted"]:
        st.markdown("**Planos Consultados:**")
        for plan in list(stats["plans_consulted"])[:5]:
            st.markdown(f"‚Ä¢ {plan}")
    
    # Tempo de sess√£o
    session_duration = datetime.now() - stats["start_time"]
    st.metric("Tempo de Sess√£o", f"{session_duration.seconds // 60} min")
    
    st.markdown("---")
    
    # Filtros avan√ßados
    with st.expander("üîç Filtros Avan√ßados"):
        selected_plan = st.selectbox(
            "Tipo de Plano:",
            ["Todos", "Cl√°ssico", "Especial", "Executivo", "Direto"]
        )
        
        selected_region = st.selectbox(
            "Regi√£o:",
            ["Todas", "Capital", "Interior 1", "Interior 2", "Interior 3"]
        )
        
        age_range = st.slider(
            "Faixa Et√°ria:",
            min_value=18,
            max_value=65,
            value=(25, 45),
            step=5
        )
        
        if st.button("üîç Buscar com Filtros", type="primary"):
            filter_query = f"Planos {selected_plan} na regi√£o {selected_region} para idades entre {age_range[0]} e {age_range[1]} anos"
            st.session_state.pending_query = filter_query
            st.rerun()
    
    st.markdown("---")
    
    # Controles
    st.markdown("### ‚öôÔ∏è Controles")
    
    if st.button("üóëÔ∏è Limpar Conversa", type="secondary", use_container_width=True):
        st.session_state.messages = []
        st.session_state.chat_history = ChatMessageHistory()
        st.session_state.session_stats = {
            "queries_count": 0,
            "price_queries": 0,
            "plans_consulted": set(),
            "start_time": datetime.now()
        }
        st.success("‚úÖ Conversa limpa!")
        st.rerun()
    
    if st.button("üìã Exportar Hist√≥rico", use_container_width=True):
        # Prepara dados para exporta√ß√£o
        export_data = {
            "sessao": {
                "inicio": stats["start_time"].isoformat(),
                "consultas": stats["queries_count"],
                "consultas_precos": stats["price_queries"],
                "planos_consultados": list(stats["plans_consulted"])
            },
            "historico": [
                {
                    "role": msg["role"],
                    "content": msg["content"],
                    "timestamp": datetime.now().isoformat()
                }
                for msg in st.session_state.messages
            ]
        }
        
        st.download_button(
            label="‚¨áÔ∏è Baixar JSON",
            data=json.dumps(export_data, indent=2, ensure_ascii=False),
            file_name=f"sessao_sdr_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
            mime="application/json"
        )
    
    st.markdown("---")
    
    # Informa√ß√µes do sistema
    st.markdown("### ‚ÑπÔ∏è Sistema")
    st.markdown("""
    **Vers√£o:** 4.0 Professional  
    **Modelo:** Gemini-2.0-Flash  
    **Base:** Qualicorp/SulAm√©rica  
    **Atualiza√ß√£o:** Jul/2025
    """)

# --- Processa consulta pendente ---
if hasattr(st.session_state, 'pending_query'):
    pending_query = st.session_state.pending_query
    delattr(st.session_state, 'pending_query')
    
    # Simula o input da consulta
    st.session_state.messages.append({"role": "user", "content": pending_query})
    st.rerun()

# --- Footer ---
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "üè• Agente SDR Qualicorp/SulAm√©rica | Desenvolvido com ‚ù§Ô∏è para resultados excepcionais"
    "</div>", 
    unsafe_allow_html=True
)

